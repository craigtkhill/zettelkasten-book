AI has some benefits. However, by my count, its harms are significantly more numerous.

## Amplifies the Dunning-Kruger Effect
The Dunning-Kruger effect is a cognitive bias where people with limited knowledge or skill in a particular area tend to overestimate their competence in that domain. Thanks to AI, it is now possible to write entire reports and documents on topics you know nothing about. Just look at Curls' problem with [AI-generated slop security reports](https://www.theregister.com/2025/05/07/curl_ai_bug_reports/). Now, it's easier than ever to be bad at something while simultaneously thinking you're great and without doing the hard work to get better, you'll never improve.

## AI is an Existential Risk
The [AI Risk Repository](https://airisk.mit.edu/) lists over 1600 potential risks that advanced AI systems could pose. AI has quietly ignited an arms race between nation-states for dominance. All of the world's leaders will have to go along for a very long time without acting stupidly to prevent the fall of humanity (probably of which is; unlikely). AI has already transformed the battlefield of Ukraine, making whole classes of equipment like naval ships obsolete and others like tanks less effective, resulting in a stalemate [^1]. In a total war, the use of AI to gain a battlefield advantage is always on the table, even with the catastrophic risks. Nuclear weapons had the advantage of mutually assured destruction. With AI, humans in their fight for survival will escalate its use, unleashing more potent killing machines until their last stand. I'm not saying we end up with a Terminator-like scenario, but the realistic scenario of constant attack from 1000s of aerial drones and machine gun-toting robodogs is highly likely. If we do not achieve world peace soon, our stupidity will lead us to make AI that destroys the world.

## AI Can't Replace Understanding
With AI, you can work very quickly. You can do stuff very quickly, and you won't even have to understand how you did it. If you don't understand something well, it's difficult for you to prompt AI successfully to create an accurate mental model of it. Remember, AI only knows what it has seen before and the context it is provided; humans can embody a far greater amount of context of the problems they are working on. Writing the code, or at least understanding what has been written, means you are actively modelling the problem. If you delegate that hard thinking to AI, without understanding the problem, getting to an accurate solution will be more difficult. It's all too easy to get AI to generate slop based on whatever limited context it has access to, have it hide the details, let it make decisions based on this shaky ground, and then give answers that you foolishly trust because you told it "don't make mistakes" in the prompt. No one knows how it got there, whether it is accurate, and you have learned nothing.  Even if you move more slowly, it is important to figure stuff out for yourself. Ignorance accumulates both technical and conceptual debt, and you will find yourself unable to distinguish between working solutions and elaborate failures. So if it's important, invest the time to fully understand the problem and solution spaces.

- AI introduces safety concerns
- AI harms problem-solving abilities
- AI impedes skills development
- AI limits idea modeling and conceptualization
- AI disrupts the deep workflow
- AI provides no advantage in many cases
- AI degrades code quality
- AI creates security vulnerabilities
- Natural language is imprecise for AI communication
- AI can slow down work processes
- AI introduces indeterminism and unpredictability
- AI makes work more stressful
- AI reduces productivity through hive-mind effects
- AI threatens job security
- AI stifles creativity
- AI reduces enjoyment and fun in work
- AI overfits to benchmarks rather than real performance
- AI inherits and amplifies human flaws

[^1]: As of writing, Russia is slowly advancing, but at a pace slower than the First World War.
